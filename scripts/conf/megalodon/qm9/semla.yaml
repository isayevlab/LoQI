run_name: 'semla_qm9'
outdir: /home/fnikitin/Megalodon/results
resume: null
ema: True
wandb_params:
  mode: 'disabled'  # disabled, offline, online
  group: 'qm9'
  project: 'Megalodon'

data:
  dataset_root: "/home/fnikitin/Megalodon/data/qm9"
  processed_folder: "processed"
  batch_size: &batch_size 128
  inference_batch_size: 128
  removed_h: False
  data_loader_type: "standard"
  aug_rotations: False
  scale_coords: &scale_coords 1.723299503326416

loss:
  variables: #! TODO can try mean
    - variable_name: 'x'
      loss_scale: 1.0
      aggregate: 'mean'
      continuous: True
      use_distance: null
      distance_scale: 0
    - variable_name: 'h'
      loss_scale: 0.2
      aggregate: 'mean'
      continuous: False
    - variable_name: 'edge_attr'
      loss_scale: 1.0
      aggregate: 'mean'
      continuous: False
    - variable_name: 'charges'
      loss_scale: 0.2
      aggregate: 'mean'
      continuous: False

interpolant:
  timesteps: &timesteps 100
  time_type: &time_type "continuous" #["discrete, "continuous]
  scheduler_type: &scheduler_type "linear" #["cosine_adaptive, "linear"]
  sample_time_method: "beta" # ["symmetric", "uniform", "stab_mode", "logit_normal", "beta"]
  sample_time_discretization: "log"
  sample_time_mean: 0 # Used in stab_mode and logit_normal
  sample_time_scale: 0.81 # Used in stab_mode and logit_normal
  global_variable_name: 'h' # variable that is specficed below to be used for sampling time and loss sampling
  min_t: &min_t 1e-5
  variables:
    - variable_name: 'x'
      interpolant_type: 'continuous_flow_matching' #["continuous_diffusion", "continuous_flow_matching"]
      optimal_transport: 'equivariant_ot' #'scale_ot'
      prior_type: 'gaussian'
      timesteps: *timesteps
      num_classes: 3
      scheduler_type: *scheduler_type
      scheduler_cut: False
      time_type: *time_type
      min_t: *min_t
      com_free: True
      noise_sigma: 0.2
      inference_noise_sigma: 0.

    - variable_name: 'h'
      interpolant_type: 'discrete_flow_matching' #["discrete_diffusion", "discrete_flow_matching"]
      prior_type: 'uniform' #['uniform', 'mask', 'custom']
      custom_prior: '${data.dataset_root}/processed/train_atom_types_h.npy'
      timesteps: *timesteps
      num_classes: &num_atoms 17
      scheduler_type: *scheduler_type
      scheduler_cut: False
      time_type: *time_type
      min_t: *min_t
    - variable_name: 'edge_attr'
      interpolant_type: 'discrete_flow_matching' #["discrete_diffusion", "discrete_flow_matching"]
      prior_type: 'uniform'
      custom_prior: '${data.dataset_root}/processed/train_bond_types_h.npy'
      timesteps: *timesteps
      num_classes: 5
      scheduler_type: *scheduler_type
      scheduler_cut: False
      time_type: *time_type
      min_t: *min_t
    - variable_name: 'charges'
      interpolant_type: 'discrete_flow_matching' #["discrete_diffusion", "discrete_flow_matching"]
      prior_type: 'uniform'
      custom_prior: '${data.dataset_root}/processed/train_charges_prior.npy' #! had to manually create the marginal (h_prior*charge_h_prior[:, None]).sum(0)
      timesteps: *timesteps
      scheduler_type: *scheduler_type
      scheduler_cut: False
      time_type: *time_type
      min_t: *min_t
      concat: 'h'
      num_classes: 6
      offset: 2



dynamics:
  model_name: "semla"
  model_args:
    d_model: 384
    vocab_size: 17
    n_atom_feats: 18
    d_edge: 128
    n_edge_types: 5
    self_cond: True
    size_emb: 64
    max_atoms: 256
    dynamics_args:
      d_model: 384
      d_message: 128
      n_coord_sets: 64
      n_layers: 12
      n_attn_heads: 32
      d_message_hidden: 128
      d_edge: 128
      bond_refine: True
      self_cond: True
      coord_norm: "length"
  wrapper_args: null

self_conditioning: null

sample:
  node_distribution: "${data.dataset_root}/processed/train_n_h.pickle" # null

train:
  seed: 42
  gpus: 1
  n_epochs: 200
  enable_progress_bar: True
  gradient_clip_value: 1.0
  log_freq: 50
  val_freq: 5
  checkpoint_monitor: mol_stable
  checkpoint_monitor_mode: max
  checkpoint_every_n_train_steps: 500

evaluation:
  type: molecules
  batch_size: 200
  n_molecules: 400
  scale_coords: *scale_coords
  timesteps: *timesteps
  compute_2D_metrics: True
  compute_3D_metrics: True
  compute_train_data_metrics: True
  compute_energy_metrics: False
  energy_metrics_args: null
  preserve_aromatic: False  # QM9 dataset uses Kekule representation


optimizer:
  type: adamw
  lr: 1.e-4
  weight_decay: 1.e-12
  amsgrad: True

lr_scheduler:
  type: linear_warmup
  initial_lr: 1.e-5
  final_lr: 1.e-4
  num_warmup_steps: 1000
  interval: step
  frequency: 1
